{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ccd7466-f592-459f-aa01-4316cecd46b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Data (salary > 10000):\n+---+---------+----------+----------+------+-------------------+-----------+------+\n| id|firstName|middleName|  lastName|gender|          birthDate|        ssn|salary|\n+---+---------+----------+----------+------+-------------------+-----------+------+\n|  1|   Pennie|     Carry|Hirschmann|     F|1955-07-02 04:00:00|981-43-9345| 56172|\n|  2|       An|     Amira|    Cowper|     F|1992-02-08 05:00:00|978-97-8086| 40203|\n|  3|    Quyen|    Marlen|      Dome|     F|1970-10-11 04:00:00|957-57-8246| 53417|\n|  4|  Coralie|  Antonina|   Marshal|     F|1990-04-11 04:00:00|963-39-4885| 94727|\n|  5|   Terrie|      Wava|     Bonar|     F|1980-01-16 05:00:00|964-49-8051| 79908|\n+---+---------+----------+----------+------+-------------------+-----------+------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "data = spark.read.format(\"delta\").load(\"dbfs:/user/hive/warehouse/export\")\n",
    "# 1. **Filtering data**: Filter employees who have a salary greater than 10000\n",
    "filtered_data = data.filter(col(\"salary\") > 10000)\n",
    "print(\"Filtered Data (salary > 10000):\")\n",
    "filtered_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c87d333-fe20-4aeb-b9c8-bb674d8c44e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with Calculated Age:\n+---+---------+----------+----------+------+-------------------+-----------+------+---+\n| id|firstName|middleName|  lastName|gender|          birthDate|        ssn|salary|age|\n+---+---------+----------+----------+------+-------------------+-----------+------+---+\n|  1|   Pennie|     Carry|Hirschmann|     F|1955-07-02 04:00:00|981-43-9345| 56172| 69|\n|  2|       An|     Amira|    Cowper|     F|1992-02-08 05:00:00|978-97-8086| 40203| 32|\n|  3|    Quyen|    Marlen|      Dome|     F|1970-10-11 04:00:00|957-57-8246| 53417| 54|\n|  4|  Coralie|  Antonina|   Marshal|     F|1990-04-11 04:00:00|963-39-4885| 94727| 34|\n|  5|   Terrie|      Wava|     Bonar|     F|1980-01-16 05:00:00|964-49-8051| 79908| 44|\n+---+---------+----------+----------+------+-------------------+-----------+------+---+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year,current_date\n",
    "# 2. **Adding a new column**: Calculate age from birthdate\n",
    "# Get the current year and subtract birth year to calculate age\n",
    "current_year = year(current_date())\n",
    "data_with_age = filtered_data.withColumn(\"age\", current_year - year(col(\"birthDate\")))\n",
    "print(\"Data with Calculated Age:\")\n",
    "data_with_age.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79ba0358-4208-40a4-854f-a044e2d5d359",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with Salary After Tax Deduction:\n+---+---------+----------+----------+------+-------------------+-----------+------+---+------------------+\n| id|firstName|middleName|  lastName|gender|          birthDate|        ssn|salary|age|  salary_after_tax|\n+---+---------+----------+----------+------+-------------------+-----------+------+---+------------------+\n|  1|   Pennie|     Carry|Hirschmann|     F|1955-07-02 04:00:00|981-43-9345| 56172| 69|44937.600000000006|\n|  2|       An|     Amira|    Cowper|     F|1992-02-08 05:00:00|978-97-8086| 40203| 32|           32162.4|\n|  3|    Quyen|    Marlen|      Dome|     F|1970-10-11 04:00:00|957-57-8246| 53417| 54|42733.600000000006|\n|  4|  Coralie|  Antonina|   Marshal|     F|1990-04-11 04:00:00|963-39-4885| 94727| 34|           75781.6|\n|  5|   Terrie|      Wava|     Bonar|     F|1980-01-16 05:00:00|964-49-8051| 79908| 44|           63926.4|\n+---+---------+----------+----------+------+-------------------+-----------+------+---+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# 3. Adding another new column: Calculate salary after a 20% tax deduction\n",
    "data_with_tax = data_with_age.withColumn(\"salary_after_tax\", col(\"salary\") * 0.8)\n",
    "print(\"Data with Salary After Tax Deduction:\")\n",
    "data_with_tax.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ec9747e-87c3-48fa-b2b9-c99193d7f8e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with Renamed Columns:\n+---+---------+----------+----------+------+-------------------+----------------------+-------------+---+------------------+\n| id|firstName|middleName|  lastName|gender|          birthDate|social_security_number|annual_salary|age|  salary_after_tax|\n+---+---------+----------+----------+------+-------------------+----------------------+-------------+---+------------------+\n|  1|   Pennie|     Carry|Hirschmann|     F|1955-07-02 04:00:00|           981-43-9345|        56172| 69|44937.600000000006|\n|  2|       An|     Amira|    Cowper|     F|1992-02-08 05:00:00|           978-97-8086|        40203| 32|           32162.4|\n|  3|    Quyen|    Marlen|      Dome|     F|1970-10-11 04:00:00|           957-57-8246|        53417| 54|42733.600000000006|\n|  4|  Coralie|  Antonina|   Marshal|     F|1990-04-11 04:00:00|           963-39-4885|        94727| 34|           75781.6|\n|  5|   Terrie|      Wava|     Bonar|     F|1980-01-16 05:00:00|           964-49-8051|        79908| 44|           63926.4|\n+---+---------+----------+----------+------+-------------------+----------------------+-------------+---+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# 4. Renaming columns: Rename 'ssn' to 'social_security_number' and 'salary' to 'annual_salary'\n",
    "renamed_data = data_with_tax.withColumnRenamed(\"ssn\", \"social_security_number\").withColumnRenamed(\"salary\", \"annual_salary\")\n",
    "print(\"Data with Renamed Columns:\")\n",
    "renamed_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dd6182e-de72-4667-b844-03206fad5a64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with Salary Categories:\n+---+---------+----------+----------+------+-------------------+----------------------+-------------+---+------------------+---------------+\n| id|firstName|middleName|  lastName|gender|          birthDate|social_security_number|annual_salary|age|  salary_after_tax|salary_category|\n+---+---------+----------+----------+------+-------------------+----------------------+-------------+---+------------------+---------------+\n|  1|   Pennie|     Carry|Hirschmann|     F|1955-07-02 04:00:00|           981-43-9345|        56172| 69|44937.600000000006|           High|\n|  2|       An|     Amira|    Cowper|     F|1992-02-08 05:00:00|           978-97-8086|        40203| 32|           32162.4|         Medium|\n|  3|    Quyen|    Marlen|      Dome|     F|1970-10-11 04:00:00|           957-57-8246|        53417| 54|42733.600000000006|           High|\n|  4|  Coralie|  Antonina|   Marshal|     F|1990-04-11 04:00:00|           963-39-4885|        94727| 34|           75781.6|           High|\n|  5|   Terrie|      Wava|     Bonar|     F|1980-01-16 05:00:00|           964-49-8051|        79908| 44|           63926.4|           High|\n+---+---------+----------+----------+------+-------------------+----------------------+-------------+---+------------------+---------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# 5. Conditional Columns: Create a new column to categorize salary\n",
    "categorized_data = renamed_data.withColumn(\n",
    "    \"salary_category\",\n",
    "    when(col(\"annual_salary\") > 50000, \"High\")\n",
    "    .when(col(\"annual_salary\") > 20000, \"Medium\")\n",
    "    .otherwise(\"Low\"))\n",
    "print(\"Data with Salary Categories:\")\n",
    "categorized_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fa2c521-49c0-423c-a084-42ec4225ee97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Salary by Gender:\n+------+-----------------+\n|gender|       avg_salary|\n+------+-----------------+\n|     F|72907.42685370741|\n+------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# 6. GroupBy and Aggregation: Calculate the average salary by gender\n",
    "salary_by_gender = renamed_data.groupBy(\"gender\").agg(\n",
    "    avg(\"annual_salary\").alias(\"avg_salary\")\n",
    ")\n",
    "print(\"Average Salary by Gender:\")\n",
    "salary_by_gender.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0af362f-aa32-4bcc-9ed1-ab50f3582627",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Sorted by Salary (Descending):\n+---+---------+----------+----------+------+-------------------+----------------------+-------------+---+------------------+\n| id|firstName|middleName|  lastName|gender|          birthDate|social_security_number|annual_salary|age|  salary_after_tax|\n+---+---------+----------+----------+------+-------------------+----------------------+-------------+---+------------------+\n| 83|  Markita|   Shellie|Baskeyfied|     F|1960-12-05 05:00:00|           993-66-4078|       134393| 64|107514.40000000001|\n|483|     Sean|    Emilia|   Bellino|     F|1980-08-17 04:00:00|           969-11-9490|       128957| 44|          103165.6|\n|686|   Karima|    Tamica|     Boden|     F|1958-04-12 05:00:00|           959-39-1344|       126968| 66|101574.40000000001|\n|326|  Verlene|   Emogene|    Biford|     F|1981-08-16 04:00:00|           945-80-8061|       126588| 43|101270.40000000001|\n|948|  Louella|     Tesha|   Cutford|     F|1970-11-16 05:00:00|           936-15-8338|       125420| 54|          100336.0|\n+---+---------+----------+----------+------+-------------------+----------------------+-------------+---+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# 7. Sorting: Sort the data by salary in descending order\n",
    "sorted_by_salary = renamed_data.orderBy(col(\"annual_salary\").desc())\n",
    "print(\"Data Sorted by Salary (Descending):\")\n",
    "sorted_by_salary.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12eeafc4-4532-4a2b-8c41-876564a956eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Columns:\n+---+---------+----------+-------------+\n| id|firstName|  lastName|annual_salary|\n+---+---------+----------+-------------+\n|  1|   Pennie|Hirschmann|        56172|\n|  2|       An|    Cowper|        40203|\n|  3|    Quyen|      Dome|        53417|\n|  4|  Coralie|   Marshal|        94727|\n|  5|   Terrie|     Bonar|        79908|\n+---+---------+----------+-------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# 8. Selecting specific columns: Select only 'id', 'firstName', 'lastName', and 'salary'\n",
    "selected_columns = renamed_data.select(\"id\", \"firstName\", \"lastName\", \"annual_salary\")\n",
    "print(\"Selected Columns:\")\n",
    "selected_columns.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f455f17-453e-4453-ac4d-6b72c750936a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with Days Since Birth:\n+---+---------+----------+----------+------+-------------------+----------------------+-------------+---+------------------+----------------+\n| id|firstName|middleName|  lastName|gender|          birthDate|social_security_number|annual_salary|age|  salary_after_tax|days_since_birth|\n+---+---------+----------+----------+------+-------------------+----------------------+-------------+---+------------------+----------------+\n|  1|   Pennie|     Carry|Hirschmann|     F|1955-07-02 04:00:00|           981-43-9345|        56172| 69|44937.600000000006|           25362|\n|  2|       An|     Amira|    Cowper|     F|1992-02-08 05:00:00|           978-97-8086|        40203| 32|           32162.4|           11992|\n|  3|    Quyen|    Marlen|      Dome|     F|1970-10-11 04:00:00|           957-57-8246|        53417| 54|42733.600000000006|           19782|\n|  4|  Coralie|  Antonina|   Marshal|     F|1990-04-11 04:00:00|           963-39-4885|        94727| 34|           75781.6|           12660|\n|  5|   Terrie|      Wava|     Bonar|     F|1980-01-16 05:00:00|           964-49-8051|        79908| 44|           63926.4|           16398|\n+---+---------+----------+----------+------+-------------------+----------------------+-------------+---+------------------+----------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import date_diff\n",
    "\n",
    "# 9. Date Difference: Calculate the number of days since the employee's birthdate\n",
    "data_with_days_since_birth = renamed_data.withColumn(\n",
    "    \"days_since_birth\", date_diff(current_date(), col(\"birthDate\"))\n",
    ")\n",
    "print(\"Data with Days Since Birth:\")\n",
    "data_with_days_since_birth.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d482d9b8-83f5-49bb-8da1-b7b3cfc0a41b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Employees Older Than 30:\n+---+---------+----------+----------+------+-------------------+----------------------+-------------+---+------------------+----------------+\n| id|firstName|middleName|  lastName|gender|          birthDate|social_security_number|annual_salary|age|  salary_after_tax|days_since_birth|\n+---+---------+----------+----------+------+-------------------+----------------------+-------------+---+------------------+----------------+\n|  1|   Pennie|     Carry|Hirschmann|     F|1955-07-02 04:00:00|           981-43-9345|        56172| 69|44937.600000000006|           25362|\n|  2|       An|     Amira|    Cowper|     F|1992-02-08 05:00:00|           978-97-8086|        40203| 32|           32162.4|           11992|\n|  3|    Quyen|    Marlen|      Dome|     F|1970-10-11 04:00:00|           957-57-8246|        53417| 54|42733.600000000006|           19782|\n|  4|  Coralie|  Antonina|   Marshal|     F|1990-04-11 04:00:00|           963-39-4885|        94727| 34|           75781.6|           12660|\n|  5|   Terrie|      Wava|     Bonar|     F|1980-01-16 05:00:00|           964-49-8051|        79908| 44|           63926.4|           16398|\n+---+---------+----------+----------+------+-------------------+----------------------+-------------+---+------------------+----------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# 10. Filtering based on age: Filter employees who are older than 30\n",
    "filtered_by_age = data_with_days_since_birth.filter(col(\"age\") > 30)\n",
    "print(\"Filtered Employees Older Than 30:\")\n",
    "filtered_by_age.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c95b621b-8ae8-443f-91ab-7c313718181a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Apply transformations to the data in Notebook 2\n",
    "\n",
    "# Transformation steps (filter, add columns, etc.) ...\n",
    "\n",
    "# Final transformed data (filtered_by_age) should be saved to a Delta table in Notebook 2\n",
    "filtered_by_age.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"default.transformed_employees\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Transfromation of Data(Export CSV File)",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}